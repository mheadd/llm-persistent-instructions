# LLM Provider Configuration
# Copy this file to .env and fill in your actual API keys

# Provider Selection
LLM_PROVIDER=ollama

# Ollama Configuration
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=phi3:mini

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic Configuration (for future use)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Azure OpenAI Configuration (for future use)
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo
AZURE_OPENAI_API_VERSION=2023-12-01-preview

# Server Configuration
PORT=3000
NODE_ENV=development

# Logging and Monitoring
LOG_LEVEL=info
LOG_PROVIDER_USAGE=true
LOG_RESPONSE_TIMES=true

# Request Timeouts (milliseconds)
HEALTH_CHECK_TIMEOUT=5000
GENERATION_TIMEOUT=120000
MAX_RETRIES=3
RETRY_DELAY=1000
