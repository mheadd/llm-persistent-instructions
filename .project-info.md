# Government AI Prototype - Persistent Instruction Layering Demo

This directory contains all the implementation files for the Government AI Prototype with **LLM Provider Abstraction**. The system now supports multiple LLM providers (Ollama, OpenAI) while maintaining specialized government service personas.

## Quick Start Commands

```bash
# Build and start all services  
docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f

# Stop all services
docker-compose down

# Test the API
curl -X POST http://localhost:3000/api/chat/unemployment-benefits \
  -H "Content-Type: application/json" \
  -d '{"message": "How do I apply for unemployment benefits?"}'

# Check current provider status
curl http://localhost:3000/api/provider/status

# List all available providers  
curl http://localhost:3000/api/providers

# Run tests
./test.sh
```

## Provider Configuration

```bash
# Switch to OpenAI
echo "LLM_PROVIDER=openai" > api/.env
echo "OPENAI_API_KEY=your-key-here" >> api/.env
docker-compose restart api

# Switch to Ollama (default)
echo "LLM_PROVIDER=ollama" > api/.env  
docker-compose restart api

# Test provider connectivity
curl -X POST http://localhost:3000/api/provider/test \
  -H "Content-Type: application/json" \
  -d '{"provider": "ollama"}'
```

## File Structure

### Root Directory
- `docker-compose.yml` - Multi-container orchestration
- `README.md` - Complete documentation and usage guide
- `INSTRUCTIONS.md` - Original project specifications
- `TESTING.md` - Comprehensive testing documentation
- `GITHUB-ACTIONS.md` - CI/CD pipeline documentation
- `test.sh` - Executable test runner script
- `.gitignore` - Version control exclusions

### GitHub Actions (`/.github/workflows`)
- `ci.yml` - Automated CI/CD pipeline for tests and security scans
- `TESTING.md` - Comprehensive testing documentation
- `test.sh` - Test runner script for all test categories
- `.gitignore` - Git exclusion patterns

### API Service (`/api`)
- `Dockerfile` - Container configuration for Node.js API
- `package.json` - Node.js dependencies and scripts (includes OpenAI, dotenv)
- `server.js` - Express.js application with provider abstraction and instruction layering
- `.env` - Environment configuration (API keys, provider settings)
- `.env.example` - Environment template with all configuration options

### Providers (`/api/providers`)
- `base-provider.js` - Abstract base class for all LLM providers
- `ollama-provider.js` - Ollama integration (local models)
- `openai-provider.js` - OpenAI API integration (GPT models)
- `provider-factory.js` - Factory pattern for creating provider instances

### Configuration (`/api/config`)
- `llm-config.yaml` - Provider configurations (Ollama, OpenAI)
- `llm-config-manager.js` - Configuration loading and management
- `environment-config.js` - Environment validation and setup
- `unemployment-benefits.yaml` - Unemployment benefits assistant persona
- `parks-recreation.yaml` - Parks and recreation guide persona  
- `business-licensing.yaml` - Business licensing assistant persona
- `default.yaml` - General purpose assistant persona

### Test Suite (`/api/__tests__`)
- `setup.js` - Global test configuration and helpers
- `config.test.js` - Unit tests for configuration loading
- `api.test.js` - Integration tests for API endpoints
- `performance.test.js` - Performance and load testing
- `e2e.test.js` - End-to-end workflow testing
- `providers.test.js` - **NEW**: Provider factory and validation tests
- `environment-config.test.js` - **NEW**: Environment configuration tests
- `provider-integration.test.js` - **NEW**: Provider integration workflows
- `TEST_SUMMARY.md` - **NEW**: Documentation of new test coverage

## API Endpoints

### Chat Endpoints (Existing)
| Method | Endpoint | Purpose |
|--------|----------|---------|
| GET | `/health` | Service health check |
| GET | `/api` | API information and available endpoints |
| POST | `/api/chat/unemployment-benefits` | Unemployment assistance |
| POST | `/api/chat/parks-recreation` | Parks and recreation info |
| POST | `/api/chat/business-licensing` | Business licensing guidance |
| POST | `/api/chat/default` | General purpose assistant |

### Provider Management (NEW)
| Method | Endpoint | Purpose |
|--------|----------|---------|
| GET | `/api/provider/status` | Current provider health and configuration |
| GET | `/api/providers` | List all available providers and configurations |
| POST | `/api/provider/test` | Test connectivity to a specific provider |

## Testing Overview

The project includes a comprehensive test suite with **71 total tests** covering both original functionality and new provider abstraction:

### Test Categories
- **Unit Tests (28 tests)**: Configuration loading, provider factory, environment validation
- **Integration Tests (34 tests)**: API endpoints, end-to-end workflows, provider integration  
- **Provider Tests (9 tests)**: Provider abstraction, factory pattern, validation logic
- **Performance Tests**: Response times, concurrent requests
- **Security Tests**: Dependency scanning, vulnerability detection

### Running Tests
```bash
# Run all tests (71 tests)
./test.sh

# Run specific categories
./test.sh unit         # Configuration and provider unit tests
./test.sh integration  # API and provider integration tests
./test.sh performance  # Performance benchmarks
./test.sh e2e         # End-to-end workflows
./test.sh coverage    # Full coverage report

# Run new provider tests only
npm test -- --testPathPattern="(providers|environment-config|provider-integration).test.js"
```

### Testing Features
- ✅ **Provider Abstraction Testing**: Factory pattern, configuration management
- ✅ **Environment Configuration Testing**: Variable validation, error handling  
- ✅ **Provider Integration Testing**: Complete workflows with local Ollama
- ✅ Mocked AI responses for fast, reliable testing
- ✅ Realistic government service scenarios
- ✅ Performance monitoring and benchmarking
- ✅ Cross-persona consistency validation
- ✅ Error handling and resilience testing
- ✅ Coverage reporting with HTML output

### CI/CD Pipeline
- ✅ **Comprehensive Provider Testing**: All 71 tests run on every commit
- ✅ **Expanded Test Coverage**: Unit, integration, and provider-specific tests
- ✅ **Provider Validation**: Factory pattern and configuration testing
- ✅ Automated testing on every commit to main branch
- ✅ npm audit security scanning for dependencies
- ✅ Test coverage report generation with provider metrics
- ✅ Pull request dependency review
- ✅ GitHub Actions status badges and detailed summaries

## Architecture Overview

```
Client Request → API Service → Provider Factory → [Ollama|OpenAI] → Persona Config → Response
```

The system now features **LLM Provider Abstraction** that allows seamless switching between different LLM providers while maintaining specialized government service experiences through strategic prompt engineering and configuration management.

### Provider Architecture
- **Factory Pattern**: Unified interface for creating different provider instances
- **Base Provider Class**: Standardized contract for all LLM implementations
- **Environment Configuration**: Secure API key management and provider selection
- **Health Monitoring**: Real-time provider status and connectivity checking

### Supported Providers
- **Ollama**: Local model deployment (phi3:mini, llama2, etc.)
- **OpenAI**: Cloud-based GPT models (gpt-3.5-turbo, gpt-4)
- **Extensible**: Easy framework for adding new providers

## Development Notes

- **Multi-Provider Support**: Switch between Ollama and OpenAI via environment variables
- **Backward Compatibility**: All existing persona endpoints work unchanged
- **Environment Validation**: Startup checks ensure proper configuration
- **Secure Configuration**: API keys stored in .env files (git-ignored)
- **Provider Health Checks**: Automatic connectivity and health monitoring
- **Docker Integration**: Complete containerized deployment with environment support
- **Comprehensive Testing**: 71 tests covering all functionality including providers
- The API automatically loads and caches YAML configurations
- All personas work with any configured LLM provider
- Docker Compose handles service dependencies and networking
- Comprehensive error handling and logging throughout

This prototype showcases **persistent instruction layering with provider abstraction** - a powerful technique for creating specialized AI assistants that can seamlessly work with different language models without requiring separate training or configuration for each provider.
